# AULA 08: APACHE KAFKA E STREAMING DE DADOS

## üéØ OBJETIVOS DA AULA
- Compreender os conceitos fundamentais de streaming de dados
- Entender a arquitetura do Apache Kafka
- Aprender sobre produtores, consumidores e t√≥picos
- Explorar casos de uso reais de streaming

## üìö CONCEITOS FUNDAMENTAIS

### O que √© Streaming de Dados?
**Defini√ß√£o**: Processamento cont√≠nuo de dados que chegam em tempo real, ao contr√°rio do processamento em lote (batch).

**Caracter√≠sticas**:
- **Baixa Lat√™ncia**: Dados processados em millisegundos
- **Alto Throughput**: Milh√µes de eventos por segundo
- **Escalabilidade**: Cresce horizontalmente
- **Toler√¢ncia a Falhas**: Resistente a quedas de sistema

### Por que Kafka?
**Apache Kafka** √© uma plataforma distribu√≠da de streaming que funciona como um "sistema nervoso" para dados em tempo real.

**Vantagens**:
1. **Performance**: Processa milh√µes de mensagens/segundo
2. **Durabilidade**: Dados persistidos em disco
3. **Escalabilidade**: Clusters com centenas de n√≥s
4. **Ecossistema**: Integra√ß√£o com Spark, Hadoop, etc.

## üèóÔ∏è ARQUITETURA DO KAFKA

### Componentes Principais

#### 1. Producer (Produtor)
**Fun√ß√£o**: Publica mensagens em t√≥picos
**Analogia**: Como um jornalista enviando not√≠cias para um jornal

```
Producer ‚Üí [Dados] ‚Üí Kafka Topic
```

#### 2. Consumer (Consumidor)
**Fun√ß√£o**: L√™ mensagens de t√≥picos
**Analogia**: Como um leitor assinando um jornal

```
Kafka Topic ‚Üí [Dados] ‚Üí Consumer
```

#### 3. Topic (T√≥pico)
**Fun√ß√£o**: Canal nomeado onde mensagens s√£o organizadas
**Analogia**: Como se√ß√µes de um jornal (esportes, pol√≠tica, etc.)

#### 4. Partition (Parti√ß√£o)
**Fun√ß√£o**: Divis√£o de um t√≥pico para paraleliza√ß√£o
**Analogia**: Como m√∫ltiplas impressoras produzindo o mesmo jornal

#### 5. Broker
**Fun√ß√£o**: Servidor Kafka que armazena dados
**Analogia**: Como uma distribuidora de jornais

#### 6. Cluster
**Fun√ß√£o**: Conjunto de brokers trabalhando juntos
**Analogia**: Como uma rede de distribui√ß√£o nacional

## üîÑ FLUXO DE DADOS NO KAFKA

### Processo Completo
```
1. Producer cria mensagem
2. Kafka determina parti√ß√£o (round-robin ou por chave)
3. Mensagem √© replicada entre brokers
4. Consumer l√™ mensagem do offset atual
5. Consumer confirma processamento (commit)
```

### Garantias de Entrega
1. **At most once**: Mensagem pode ser perdida, nunca duplicada
2. **At least once**: Mensagem nunca perdida, pode ser duplicada
3. **Exactly once**: Mensagem processada exatamente uma vez (ideal)

## üìä CASOS DE USO REAIS

### 1. E-commerce - Rastreamento de Atividade
**Cen√°rio**: Loja online rastreando cliques de usu√°rios
```
Website ‚Üí Kafka ‚Üí Analytics Engine ‚Üí Dashboard
```
**Benef√≠cios**: Recomenda√ß√µes em tempo real, detec√ß√£o de fraudes

### 2. Fintech - Processamento de Transa√ß√µes
**Cen√°rio**: Sistema banc√°rio processando pagamentos
```
App M√≥vel ‚Üí Kafka ‚Üí Validador ‚Üí Banco de Dados
```
**Benef√≠cios**: Processamento instant√¢neo, auditoria completa

### 3. IoT - Sensores Industriais
**Cen√°rio**: F√°brica monitorando equipamentos
```
Sensores ‚Üí Kafka ‚Üí ML Model ‚Üí Alertas
```
**Benef√≠cios**: Manuten√ß√£o preditiva, economia de custos

### 4. Media Streaming - Netflix/YouTube
**Cen√°rio**: Plataforma de v√≠deo coletando m√©tricas
```
Player ‚Üí Kafka ‚Üí Analytics ‚Üí Recomenda√ß√µes
```
**Benef√≠cios**: Melhor experi√™ncia do usu√°rio

## ‚öôÔ∏è CONFIGURA√á√ïES IMPORTANTES

### Producer Configurations
- **batch.size**: Tamanho do lote para otimizar throughput
- **linger.ms**: Tempo de espera para formar lotes
- **acks**: N√≠vel de confirma√ß√£o requerido

### Consumer Configurations
- **auto.offset.reset**: Comportamento quando n√£o h√° offset
- **enable.auto.commit**: Commit autom√°tico de offsets
- **max.poll.records**: M√°ximo de registros por poll

### Topic Configurations
- **num.partitions**: N√∫mero de parti√ß√µes
- **replication.factor**: Fator de replica√ß√£o
- **retention.ms**: Tempo de reten√ß√£o de dados

## üöÄ PADR√ïES DE DESIGN

### 1. Event Sourcing
**Conceito**: Armazenar mudan√ßas de estado como eventos
**Vantagem**: Hist√≥rico completo, possibilidade de replay

### 2. CQRS (Command Query Responsibility Segregation)
**Conceito**: Separar leitura e escrita
**Vantagem**: Otimiza√ß√£o independente de cada opera√ß√£o

### 3. Saga Pattern
**Conceito**: Transa√ß√µes distribu√≠das via eventos
**Vantagem**: Consist√™ncia eventual em microservi√ßos

## üìà MONITORAMENTO E M√âTRICAS

### M√©tricas Importantes
1. **Throughput**: Mensagens por segundo
2. **Lat√™ncia**: Tempo entre produ√ß√£o e consumo
3. **Lag**: Atraso do consumer em rela√ß√£o ao producer
4. **Disk Usage**: Uso de disco pelos brokers

### Ferramentas de Monitoramento
- **Kafka Manager**: Interface web para administra√ß√£o
- **Prometheus + Grafana**: M√©tricas e dashboards
- **Confluent Control Center**: Ferramenta comercial completa

## üéì EXERC√çCIOS CONCEITUAIS

### Exerc√≠cio 1: Design de Sistema
**Problema**: Projetar sistema de chat em tempo real para 1 milh√£o de usu√°rios
**Considere**: T√≥picos, parti√ß√µes, replica√ß√£o, consumers

### Exerc√≠cio 2: An√°lise de Caso
**Problema**: Uber precisa processar 15 milh√µes de viagens/dia
**Considere**: Lat√™ncia, throughput, consistency, availability

### Exerc√≠cio 3: Troubleshooting
**Problema**: Consumers ficando com lag alto
**Investigue**: Partitions, consumer groups, processing time

## üìö RECURSOS ADICIONAIS

### Documenta√ß√£o
- [Kafka Official Documentation](https://kafka.apache.org/documentation/)
- [Confluent Documentation](https://docs.confluent.io/)

### Livros Recomendados
- "Kafka: The Definitive Guide" - Gwen Shapira
- "Designing Data-Intensive Applications" - Martin Kleppmann

### Cursos Online
- Confluent Kafka Training
- LinkedIn Learning: Apache Kafka
- Udemy: Apache Kafka Series

## üéØ PR√ìXIMOS PASSOS

1. **Instalar Kafka**: Setup local ou uso de servi√ßos cloud
2. **Praticar**: Criar producers e consumers simples
3. **Experimentar**: Diferentes configura√ß√µes e padr√µes
4. **Integrar**: Conectar com outras ferramentas (Spark, Elasticsearch)
5. **Monitorar**: Implementar observabilidade completa

---

**Pr√≥xima Aula**: Machine Learning em Big Data com Spark MLlib
