# AULA 09: MACHINE LEARNING EM BIG DATA

## üéØ OBJETIVOS DA AULA
- Compreender os desafios de ML em grandes volumes de dados
- Entender algoritmos distribu√≠dos de Machine Learning
- Explorar Apache Spark MLlib
- Aprender sobre feature engineering em escala
- Conhecer casos de uso reais de ML em Big Data

## üìö CONCEITOS FUNDAMENTAIS

### O que √© Machine Learning em Big Data?
**Defini√ß√£o**: Aplica√ß√£o de algoritmos de aprendizado de m√°quina em datasets que s√£o grandes demais para processamento em uma √∫nica m√°quina.

**Desafios √önicos**:
- **Volume**: Datasets de terabytes ou petabytes
- **Velocidade**: Processamento em tempo real
- **Variedade**: Dados estruturados e n√£o-estruturados
- **Veracidade**: Qualidade e confiabilidade dos dados

### Por que ML Distribu√≠do?
**Necessidade**: Datasets modernos excedem capacidade de uma m√°quina

**Benef√≠cios**:
1. **Escalabilidade**: Processa datasets "infinitos"
2. **Performance**: Paraleliza√ß√£o reduz tempo de treinamento
3. **Recursos**: Utiliza clusters de centenas de m√°quinas
4. **Custo**: Mais econ√¥mico que supercomputadores

## üèóÔ∏è ARQUITETURAS DE ML DISTRIBU√çDO

### 1. Data Parallelism (Paralelismo de Dados)
**Conceito**: Mesmo modelo treinado em diferentes parti√ß√µes dos dados

```
Dataset ‚Üí Parti√ß√£o 1 ‚Üí Modelo 1 ‚Üò
       ‚Üí Parti√ß√£o 2 ‚Üí Modelo 2 ‚Üí Agrega√ß√£o ‚Üí Modelo Final
       ‚Üí Parti√ß√£o 3 ‚Üí Modelo 3 ‚Üó
```

**Vantagens**:
- Simples de implementar
- Escala bem com dados
- Funciona com algoritmos existentes

### 2. Model Parallelism (Paralelismo de Modelo)
**Conceito**: Modelo dividido entre diferentes m√°quinas

```
Dados ‚Üí Parte A do Modelo (M√°quina 1) ‚Üí Parte B do Modelo (M√°quina 2) ‚Üí Resultado
```

**Vantagens**:
- Permite modelos muito grandes
- √ötil para deep learning
- Otimiza uso de mem√≥ria

### 3. Parameter Server Architecture
**Conceito**: Servidores dedicados mant√™m par√¢metros do modelo

```
Workers ‚Üí Gradientes ‚Üí Parameter Server ‚Üí Par√¢metros Atualizados ‚Üí Workers
```

**Vantagens**:
- Sincroniza√ß√£o eficiente
- Toler√¢ncia a falhas
- Escalabilidade horizontal

## üöÄ APACHE SPARK MLLIB

### Vis√£o Geral
**MLlib** √© a biblioteca de Machine Learning distribu√≠do do Apache Spark, projetada para simplificar ML em grande escala.

**Caracter√≠sticas**:
- **APIs de Alto N√≠vel**: DataFrame-based API
- **Algoritmos Distribu√≠dos**: Implementa√ß√µes escal√°veis
- **Pipeline ML**: Workflows reproduz√≠veis
- **Integra√ß√£o**: Funciona com ecossistema Spark

### Algoritmos Dispon√≠veis

#### Classifica√ß√£o
1. **Logistic Regression**: Para problemas de classifica√ß√£o bin√°ria/multiclasse
2. **Random Forest**: Ensemble de √°rvores de decis√£o
3. **Gradient Boosting**: Algoritmo de boosting
4. **SVM**: Support Vector Machines
5. **Naive Bayes**: Classificador probabil√≠stico

#### Regress√£o
1. **Linear Regression**: Regress√£o linear cl√°ssica
2. **Ridge/Lasso**: Regress√£o com regulariza√ß√£o
3. **Random Forest Regression**: Ensemble para regress√£o
4. **Gradient Boosting Regression**: Boosting para regress√£o

#### Clustering
1. **K-Means**: Clustering baseado em centr√≥ides
2. **Gaussian Mixture Models**: Clustering probabil√≠stico
3. **LDA**: Latent Dirichlet Allocation para topic modeling

#### Sistemas de Recomenda√ß√£o
1. **ALS**: Alternating Least Squares
2. **Matrix Factorization**: Decomposi√ß√£o de matrizes

### Pipeline de ML no Spark

#### Conceitos Principais
1. **Transformer**: Transforma dados (ex: normaliza√ß√£o)
2. **Estimator**: Treina modelo a partir de dados
3. **Pipeline**: Sequ√™ncia de transformers e estimators

#### Exemplo de Pipeline
```
Dados Brutos ‚Üí Preprocessamento ‚Üí Feature Engineering ‚Üí Treinamento ‚Üí Modelo
```

**Etapas Detalhadas**:
1. **Data Loading**: Carregar dados de fontes diversas
2. **Data Cleaning**: Tratar valores nulos e outliers
3. **Feature Engineering**: Criar e selecionar features
4. **Model Training**: Treinar algoritmo escolhido
5. **Model Evaluation**: Avaliar performance
6. **Model Deployment**: Colocar em produ√ß√£o

## üõ†Ô∏è FEATURE ENGINEERING EM ESCALA

### Transforma√ß√µes Comuns

#### Para Dados Num√©ricos
1. **Normaliza√ß√£o**: Escalar valores para [0,1]
2. **Padroniza√ß√£o**: M√©dia 0, desvio padr√£o 1
3. **Binning**: Converter num√©rico em categ√≥rico
4. **Polynomial Features**: Criar features polinomiais

#### Para Dados Categ√≥ricos
1. **String Indexer**: Converter strings em √≠ndices
2. **One-Hot Encoding**: Criar vari√°veis dummy
3. **Feature Hashing**: Hash de features categ√≥ricas

#### Para Dados de Texto
1. **Tokeniza√ß√£o**: Dividir texto em palavras
2. **TF-IDF**: Term Frequency-Inverse Document Frequency
3. **Word2Vec**: Embeddings de palavras
4. **N-grams**: Sequ√™ncias de palavras

### Sele√ß√£o de Features
1. **Filter Methods**: Baseados em estat√≠sticas
2. **Wrapper Methods**: Baseados em performance do modelo
3. **Embedded Methods**: Sele√ß√£o durante treinamento

## üìä CASOS DE USO REAIS

### 1. Netflix - Sistema de Recomenda√ß√£o
**Desafio**: Recomendar filmes para 200+ milh√µes de usu√°rios
**Solu√ß√£o**: Collaborative Filtering com ALS
**Escala**: Trilh√µes de intera√ß√µes, milh√µes de t√≠tulos
**Resultado**: 80% do conte√∫do assistido vem de recomenda√ß√µes

### 2. Uber - Previs√£o de Demanda
**Desafio**: Prever demanda por corridas em tempo real
**Solu√ß√£o**: Time Series Forecasting + ML
**Escala**: Milh√µes de viagens/dia, centenas de cidades
**Resultado**: Melhor aloca√ß√£o de motoristas, menor tempo de espera

### 3. Spotify - Descoberta Musical
**Desafio**: Personalizar playlists para 400+ milh√µes usu√°rios
**Solu√ß√£o**: Deep Learning + Collaborative Filtering
**Escala**: Bilh√µes de streams, milh√µes de m√∫sicas
**Resultado**: Aumento de 30% no engagement

### 4. Fraud Detection (Bancos)
**Desafio**: Detectar fraudes em transa√ß√µes em tempo real
**Solu√ß√£o**: Ensemble Methods + Real-time Scoring
**Escala**: Milh√µes de transa√ß√µes/dia
**Resultado**: Redu√ß√£o de 60% em fraudes

## ‚öôÔ∏è OTIMIZA√á√ÉO E TUNING

### Hyperparameter Tuning
1. **Grid Search**: Busca exaustiva em grid de par√¢metros
2. **Random Search**: Busca aleat√≥ria mais eficiente
3. **Bayesian Optimization**: Busca inteligente baseada em probabilidade

### Cross-Validation Distribu√≠do
**Problema**: Valida√ß√£o em datasets grandes √© custosa
**Solu√ß√£o**: Paralelizar folds de cross-validation
**Benef√≠cio**: Reduz tempo de valida√ß√£o significativamente

### Caching e Persist√™ncia
**Estrat√©gias**:
- Cache de datasets intermedi√°rios
- Persist√™ncia de modelos treinados
- Checkpoint para training longo

## üìà AVALIA√á√ÉO DE MODELOS

### M√©tricas para Classifica√ß√£o
1. **Accuracy**: Porcentagem de predi√ß√µes corretas
2. **Precision/Recall**: Para datasets desbalanceados
3. **F1-Score**: M√©dia harm√¥nica de precision e recall
4. **AUC-ROC**: √Årea sob a curva ROC

### M√©tricas para Regress√£o
1. **RMSE**: Root Mean Square Error
2. **MAE**: Mean Absolute Error
3. **R¬≤**: Coeficiente de determina√ß√£o

### M√©tricas para Clustering
1. **Silhouette Score**: Qualidade dos clusters
2. **Inertia**: Soma das dist√¢ncias aos centr√≥ides

## üöÄ TEND√äNCIAS E FUTURO

### AutoML (Automated Machine Learning)
**Conceito**: Automatiza√ß√£o do pipeline completo de ML
**Ferramentas**: H2O.ai, DataRobot, Google AutoML
**Benef√≠cio**: Democratiza ML para n√£o-especialistas

### MLOps (Machine Learning Operations)
**Conceito**: DevOps aplicado a Machine Learning
**Inclui**: Versionamento, CI/CD, monitoramento
**Ferramentas**: MLflow, Kubeflow, TensorFlow Serving

### Federated Learning
**Conceito**: Treinar modelos sem centralizar dados
**Benef√≠cio**: Privacidade e compliance
**Aplica√ß√µes**: Mobile AI, healthcare, finance

### Edge ML
**Conceito**: Executar ML em dispositivos edge
**Benef√≠cio**: Baixa lat√™ncia, privacidade
**Desafios**: Recursos limitados, otimiza√ß√£o

## üéì EXERC√çCIOS CONCEITUAIS

### Exerc√≠cio 1: Design de Sistema
**Problema**: Sistema de recomenda√ß√£o para e-commerce com 10 milh√µes de usu√°rios
**Considere**: Algoritmos, escalabilidade, lat√™ncia, cold start

### Exerc√≠cio 2: Feature Engineering
**Problema**: Prever pre√ßos de im√≥veis usando dados p√∫blicos
**Considere**: Features geogr√°ficas, temporais, econ√¥micas

### Exerc√≠cio 3: Otimiza√ß√£o
**Problema**: Reduzir tempo de treinamento de 8 horas para 1 hora
**Considere**: Paraleliza√ß√£o, sampling, feature selection

## üìö RECURSOS ADICIONAIS

### Livros Recomendados
- "Hands-On Machine Learning" - Aur√©lien G√©ron
- "The Elements of Statistical Learning" - Hastie, Tibshirani, Friedman
- "Pattern Recognition and Machine Learning" - Christopher Bishop

### Cursos Online
- Coursera: Machine Learning Course (Andrew Ng)
- edX: MIT Introduction to Machine Learning
- Udacity: Machine Learning Engineer Nanodegree

### Frameworks e Ferramentas
- **Apache Spark MLlib**: ML distribu√≠do
- **TensorFlow**: Deep learning em escala
- **PyTorch**: Research e produ√ß√£o
- **H2O.ai**: AutoML platform
- **MLflow**: ML lifecycle management

## üéØ PR√ìXIMOS PASSOS

1. **Praticar**: Implementar algoritmos simples
2. **Experimentar**: Usar Spark MLlib em datasets reais
3. **Especializar**: Focar em domain espec√≠fico (NLP, Computer Vision, etc.)
4. **Produzir**: Colocar modelos em produ√ß√£o
5. **Continuar**: Acompanhar research e novas t√©cnicas

---

**Pr√≥xima Aula**: Deep Learning Distribu√≠do e Redes Neurais em Escala
