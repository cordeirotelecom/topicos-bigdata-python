# Aula 07 - Apache Spark: Processamento de Big Data em Memória

## 🎯 Objetivos da Aula
- Compreender a arquitetura do Apache Spark
- Configurar ambiente Spark com PySpark
- Trabalhar com RDDs e DataFrames
- Implementar transformações e ações
- Otimizar performance de jobs Spark

## 📋 Conteúdo Programático

### 1. Fundamentos do Apache Spark
- Arquitetura distribuída
- Spark Core, SQL, Streaming, MLlib
- Comparação com MapReduce

### 2. RDDs (Resilient Distributed Datasets)
- Conceitos fundamentais
- Transformações lazy
- Ações e caching

### 3. Spark SQL e DataFrames
- Structured data processing
- Catalyst optimizer
- Spark SQL queries

### 4. Performance Tuning
- Partitioning strategies
- Memory management
- Broadcast variables

## 🛠️ Atividades Práticas

### Exercício 1: RDD Operations
- Criação e manipulação de RDDs
- Transformações básicas (map, filter, reduce)
- Persistência e cache

### Exercício 2: DataFrame Analytics
- Leitura de dados estruturados
- Operações SQL
- Agregações e joins

### Exercício 3: ETL Pipeline
- Extract, Transform, Load
- Data quality checks
- Output optimization

## 📊 Projeto Prático
Pipeline de análise de dados de vendas e-commerce:
- Processamento de logs de clickstream
- Análise de comportamento de usuários
- Geração de insights de negócio

## 📚 Material de Apoio
- [Documentação PySpark](https://spark.apache.org/docs/latest/api/python/)
- [Spark SQL Guide](https://spark.apache.org/docs/latest/sql-programming-guide.html)
- [Performance Tuning](https://spark.apache.org/docs/latest/tuning.html)

## 🎯 Próxima Aula
Aula 08 - Spark MLlib e Machine Learning
