# ğŸš€ TÃ³picos de Big Data em Python

**Plataforma educacional completa para aprendizado de Big Data com Apache Hadoop, Spark, anÃ¡lise de dados e casos prÃ¡ticos de Santa Catarina.**

[![Status](https://img.shields.io/badge/Status-Online-brightgreen)](https://datascience-pro.netlify.app)
[![Hadoop](https://img.shields.io/badge/Hadoop-3.3.4-orange)](https://hadoop.apache.org/)
[![Spark](https://img.shields.io/badge/Spark-3.5.0-red)](https://spark.apache.org/)
[![Python](https://img.shields.io/badge/Python-3.8+-blue)](https://python.org/)
[![QuestÃµes](https://img.shields.io/badge/Quest%C3%B5es-40+-green)](questoes-concurso-bigdata.md)

## ğŸŒŸ Recursos Principais

### ğŸ˜ Apache Hadoop - LaboratÃ³rio Completo
- **ğŸ‡§ğŸ‡· 100% em PortuguÃªs** - ExplicaÃ§Ãµes didÃ¡ticas e claras
- **ğŸ—ºï¸ MapReduce PrÃ¡tico** - Exemplos funcionais com Python
- **ğŸ’¾ Tutorial HDFS** - Sistema de arquivos distribuÃ­do
- **ğŸ’» Guia de InstalaÃ§Ã£o** - Passo a passo no Ubuntu
- **ğŸ‹ï¸ ExercÃ­cios Hands-on** - Datasets reais para praticar

### âš¡ Apache Spark - Processamento DistribuÃ­do
- **PySpark Completo** - Tutoriais prÃ¡ticos e avanÃ§ados
- **Spark SQL** - AnÃ¡lise de dados com SQL
- **Streaming** - Processamento em tempo real
- **Machine Learning** - MLlib para Big Data

### ğŸ“Š AnÃ¡lise de Dados CientÃ­ficos
- **Upload Inteligente** - CSV, JSON, Excel
- **AnÃ¡lise AutomÃ¡tica** - EstatÃ­sticas e correlaÃ§Ãµes
- **VisualizaÃ§Ãµes AvanÃ§adas** - GrÃ¡ficos interativos
- **RelatÃ³rios Completos** - ExportaÃ§Ã£o de resultados

### ğŸ“ ConteÃºdo AcadÃªmico
- **15 Aulas Completas** - Do bÃ¡sico ao avanÃ§ado
- **5 MÃ³dulos Especializados** - Fundamentos, Hadoop, Spark, Pandas, ML/DL
- **40+ QuestÃµes de Concurso** - PreparaÃ§Ã£o para concursos pÃºblicos
- **Casos PrÃ¡ticos SC** - Exemplos reais de Santa Catarina

## ğŸŒ Acesso Online



**ğŸš€ Site Principal:** https://datascience-pro.netlify.app
**ğŸ˜ LaboratÃ³rio Hadoop:** https://datascience-pro.netlify.app/aulas/aula06-hadoop-intro/laboratorio-hadoop-pratico.html
**ï¿½ QuestÃµes de Concurso:** https://datascience-pro.netlify.app/questoes-concurso-bigdata.md

## ğŸš€ Status Atual - TUDO FUNCIONANDO! âœ…

- âœ… **Site Online e Responsivo**
- âœ… **LaboratÃ³rio Hadoop 100% PortuguÃªs** 
- âœ… **MapReduce com Python Funcionando**
- âœ… **HDFS Tutorial DidÃ¡tico Completo**
- âœ… **Apache Spark PySpark Tutoriais**
- âœ… **15 Aulas Estruturadas**
- âœ… **40+ QuestÃµes de Concurso PÃºblico**
- âœ… **5 MÃ³dulos Especializados**
- âœ… **Design Profissional e Responsivo**
- âœ… **Deploy Netlify AutomÃ¡tico**

**Ãšltima atualizaÃ§Ã£o: 29/09/2025 - ConteÃºdo expandido e otimizado!** ğŸ‰

## ğŸ“š Estrutura do Curso

### ğŸ“– Aulas Principais (15 Aulas)
```
aulas/
â”œâ”€â”€ aula01-intro-bigdata/          # IntroduÃ§Ã£o e conceitos fundamentais
â”œâ”€â”€ aula02-iot-computacao/         # IoT e computaÃ§Ã£o ubÃ­qua
â”œâ”€â”€ aula03-cloud-streaming/        # Cloud computing e streaming
â”œâ”€â”€ aula04-revisao-python/         # RevisÃ£o Python para Big Data
â”œâ”€â”€ aula05-analise-dados-resumo/   # AnÃ¡lise de dados e estatÃ­stica
â”œâ”€â”€ aula06-hadoop-intro/           # Apache Hadoop - IntroduÃ§Ã£o
â”œâ”€â”€ aula07-spark-fundamentals/     # Apache Spark - Fundamentos
â”œâ”€â”€ aula08-kafka-streaming/        # Apache Kafka - Streaming
â”œâ”€â”€ aula09-ml-bigdata/            # Machine Learning para Big Data
â”œâ”€â”€ aula10-ml-distribuido/        # ML DistribuÃ­do
â”œâ”€â”€ aula11-graph-analytics/       # AnÃ¡lise de Grafos
â”œâ”€â”€ aula12-databricks-cloud/      # Databricks e Cloud
â”œâ”€â”€ aula13-deep-learning-bigdata/ # Deep Learning em Big Data
â”œâ”€â”€ aula14-edge-computing-iot/    # Edge Computing e IoT
â””â”€â”€ aula15-quantum-computing/     # ComputaÃ§Ã£o QuÃ¢ntica
```

### ğŸ¯ MÃ³dulos Especializados (5 MÃ³dulos)
```
aulas/
â”œâ”€â”€ modulo1-fundamentos/          # Fundamentos de Big Data
â”œâ”€â”€ modulo2-hadoop/              # Ecossistema Hadoop completo
â”œâ”€â”€ modulo3-spark/               # Apache Spark avanÃ§ado
â”œâ”€â”€ modulo4-pandas/              # Pandas para anÃ¡lise de dados
â””â”€â”€ modulo5-ml-dl/               # Machine Learning e Deep Learning
```

### ï¿½ QuestÃµes de Concurso (40+ QuestÃµes)
- **Baseadas em concursos reais** - CESPE, FCC, VUNESP, FGV, CONSULPLAN
- **NÃ­vel tÃ©cnico elevado** - Analista de TI, Analista de Sistemas
- **Cobertura completa** - Hadoop, Spark, Kafka, NoSQL, ML, GovernanÃ§a
- **ExplicaÃ§Ãµes detalhadas** - Conceitos e aplicaÃ§Ã£o prÃ¡tica
- **Caso governamental** - Tribunal de Contas de SC

## ğŸ¯ Destaques do Projeto

### ğŸ† **Big Data mais Completo em PortuguÃªs**
- Tutorial Hadoop passo-a-passo com instalaÃ§Ã£o Ubuntu
- PySpark com exemplos prÃ¡ticos de processamento distribuÃ­do
- Kafka para streaming de dados em tempo real
- Machine Learning distribuÃ­do com MLlib

### ğŸ“Š **Casos Reais de Santa Catarina**
- AnÃ¡lise de trÃ¡fego da Ponte HercÃ­lio Luz
- Sistemas IoT de monitoramento urbano em SÃ£o JosÃ©
- Dados turÃ­sticos de FlorianÃ³polis
- Frota de veÃ­culos do DETRAN-SC
- Mercado imobiliÃ¡rio da Grande FlorianÃ³polis

### ğŸ“ **PreparaÃ§Ã£o para Concursos**
- 40+ questÃµes baseadas em provas reais
- Cobertura de tecnologias avanÃ§adas: Atlas, Ranger, Knox, Ambari
- GovernanÃ§a de dados e compliance LGPD
- Arquiteturas Lambda e Kappa
- CenÃ¡rios governamentais prÃ¡ticos
## ğŸš€ InstalaÃ§Ã£o e Primeiros Passos

### ğŸ“‹ PrÃ©-requisitos
- **Python 3.8+** - [Download oficial](https://python.org/downloads)
- **Java 8 ou 11** - [OpenJDK](https://adoptium.net/) (para PySpark)
- **Git** - [Download](https://git-scm.com/downloads)

### âš¡ InstalaÃ§Ã£o RÃ¡pida (5 minutos)
```bash
# 1. Clone o repositÃ³rio
git clone https://github.com/cordeirotelecom/topicos-bigdata-python.git
cd topicos-bigdata-python

# 2. Crie ambiente virtual
python -m venv venv
# Windows: venv\Scripts\activate
# Linux/macOS: source venv/bin/activate

# 3. Instale dependÃªncias
pip install -r requirements.txt

# 4. Teste PySpark
python -c "import pyspark; print('âœ… PySpark OK!')"

# 5. Inicie Jupyter
jupyter lab
```

### ğŸ“– Primeiros Passos
1. **Abra Jupyter Lab** e navegue atÃ© `aulas/aula01-intro-bigdata/`
2. **Execute os exemplos** interativos de anÃ¡lise de dados
3. **Explore o laboratÃ³rio Hadoop** em `aulas/aula06-hadoop-intro/`
4. **Teste questÃµes de concurso** em `questoes-concurso-bigdata.md`

## ğŸ”§ Tecnologias e Ferramentas

### ğŸ **Python e Big Data**
```python
# Principais bibliotecas utilizadas
pandas>=2.1.0          # AnÃ¡lise de dados
numpy>=1.24.0           # ComputaÃ§Ã£o numÃ©rica
pyspark>=3.5.0          # Big Data processing
scikit-learn>=1.3.0     # Machine Learning
matplotlib>=3.7.0       # VisualizaÃ§Ã£o
seaborn>=0.12.0         # GrÃ¡ficos estatÃ­sticos
jupyter>=1.0.0          # Notebooks interativos
```

### ğŸ› ï¸ **Ecossistema Hadoop**
- **HDFS** - Sistema de arquivos distribuÃ­do
- **MapReduce** - Processamento paralelo
- **YARN** - Gerenciamento de recursos
- **Hive** - SQL sobre Hadoop
- **HBase** - Banco NoSQL distribuÃ­do
- **Sqoop** - IntegraÃ§Ã£o com SGBDs

### âš¡ **Apache Spark**
- **PySpark** - API Python para Spark
- **Spark SQL** - Consultas SQL distribuÃ­das
- **Spark Streaming** - Processamento de streams
- **MLlib** - Machine Learning distribuÃ­do
- **GraphX** - AnÃ¡lise de grafos

### ğŸŒŠ **Streaming e Tempo Real**
- **Apache Kafka** - Plataforma de streaming
- **Apache Storm** - Processamento de streams
- **Apache Flink** - Stream processing avanÃ§ado

## ğŸ’¡ Casos de Uso PrÃ¡ticos

### ğŸ›ï¸ **Setor PÃºblico**
- **TransparÃªncia governamental** - AnÃ¡lise de gastos pÃºblicos
- **Smart cities** - Monitoramento urbano com IoT
- **SaÃºde pÃºblica** - AnÃ¡lise epidemiolÃ³gica
- **EducaÃ§Ã£o** - MÃ©tricas de desempenho escolar
- **SeguranÃ§a** - AnÃ¡lise de dados criminais

### ğŸ¢ **Setor Privado**
- **E-commerce** - Sistemas de recomendaÃ§Ã£o
- **FinanÃ§as** - DetecÃ§Ã£o de fraudes
- **TelecomunicaÃ§Ãµes** - AnÃ¡lise de trÃ¡fego de rede
- **Varejo** - AnÃ¡lise de comportamento do consumidor
- **LogÃ­stica** - OtimizaÃ§Ã£o de rotas e entregas

### ğŸ“ **AcadÃªmico e Pesquisa**
- **PreparaÃ§Ã£o para concursos** - 40+ questÃµes reais
- **DissertaÃ§Ãµes e teses** - Casos prÃ¡ticos para pesquisa
- **Cursos tÃ©cnicos** - Material didÃ¡tico completo
- **ExtensÃ£o universitÃ¡ria** - Projetos comunitÃ¡rios

## ğŸ“š Livro Digital: Big Data em Python

*"Big Data em Python: Casos PrÃ¡ticos de Santa Catarina - Um guia educacional atravÃ©s de storytelling com casos reais"*

### ğŸ“– **5 CapÃ­tulos Narrativos com Patrick**
1. **O Despertar dos Dados** - Patrick descobre Big Data em FlorianÃ³polis
2. **IoT e Cidades Inteligentes** - Patrick explora sensores em SÃ£o JosÃ©  
3. **AnÃ¡lise de Dados TurÃ­sticos** - Patrick desvenda padrÃµes do turismo
4. **Apache Spark em AÃ§Ã£o** - Patrick processa dados do DETRAN-SC
5. **Machine Learning Aplicado** - Patrick prevÃª preÃ§os imobiliÃ¡rios

### ğŸ­ **Metodologia Narrativa Ãšnica**
- **Patrick** como protagonista consistente em todos os capÃ­tulos
- **Storytelling educativo** para aprendizado envolvente
- **Menos cÃ³digo, mais explicaÃ§Ã£o** - foco na compreensÃ£o
- **Contexto local** mas aplicÃ¡vel universalmente
- **80+ skills** essenciais para o mercado de trabalho

## ğŸ¤ Como Contribuir

### ğŸ“ **Tipos de ContribuiÃ§Ã£o**
- **Melhorar explicaÃ§Ãµes** - Tornar conceitos mais claros
- **Adicionar casos prÃ¡ticos** - Exemplos de sua regiÃ£o
- **Corrigir erros** - Bugs, typos, links quebrados
- **Expandir questÃµes** - Mais questÃµes de concursos reais
- **Traduzir conteÃºdo** - VersÃµes em outros idiomas

### ğŸ› ï¸ **Como Contribuir**
```bash
# 1. Fork o projeto no GitHub
# 2. Clone seu fork
git clone https://github.com/SEU-USUARIO/topicos-bigdata-python.git

# 3. Crie uma branch para sua contribuiÃ§Ã£o
git checkout -b minha-contribuicao

# 4. FaÃ§a suas alteraÃ§Ãµes e commit
git add .
git commit -m "Adiciona: Nova explicaÃ§Ã£o sobre Kafka"

# 5. Push e abra Pull Request
git push origin minha-contribuicao
```

## ğŸ¯ PÃºblico-Alvo

### ğŸ‘¨â€ğŸ“ **Estudantes**
- **GraduaÃ§Ã£o** em CiÃªncia da ComputaÃ§Ã£o, Engenharia, AdministraÃ§Ã£o
- **PÃ³s-graduaÃ§Ã£o** em Big Data, Data Science, BI
- **Cursos tÃ©cnicos** em informÃ¡tica e anÃ¡lise de dados
- **Autodidatas** interessados em tecnologia e dados

### ğŸ‘¨â€ğŸ’¼ **Profissionais**
- **Analistas de dados** iniciantes e intermediÃ¡rios
- **Desenvolvedores** que querem aprender Big Data
- **Gestores de TI** buscando conhecimento tÃ©cnico
- **Consultores** em transformaÃ§Ã£o digital

### ğŸ›ï¸ **Setor PÃºblico**
- **Analistas de TI** em concursos pÃºblicos
- **Gestores pÃºblicos** interessados em inovaÃ§Ã£o
- **Auditores** que trabalham com grandes volumes de dados
- **TÃ©cnicos** em Ã³rgÃ£os de controle e transparÃªncia

## ğŸ“ Suporte e Comunidade

### ğŸ’¬ **Canais de ComunicaÃ§Ã£o**
- **GitHub Issues** - [Reportar problemas](https://github.com/cordeirotelecom/topicos-bigdata-python/issues)
- **GitHub Discussions** - [FÃ³rum da comunidade](https://github.com/cordeirotelecom/topicos-bigdata-python/discussions)
- **Site oficial** - [https://datascience-pro.netlify.app](https://datascience-pro.netlify.app)

### ğŸ“š **Recursos Adicionais**
- **[Guia de InstalaÃ§Ã£o Completo](INSTALACAO_COMPLETA.md)** - Tutorial detalhado
- **[Guia de IA](GUIA_INTELIGENCIA_ARTIFICIAL.md)** - Machine Learning e Deep Learning
- **[Casos PrÃ¡ticos](CASOS_PRATICOS.md)** - Projetos completos prontos
- **[QuestÃµes de Concurso](questoes-concurso-bigdata.md)** - 40+ questÃµes reais

## ğŸ“„ LicenÃ§a e Uso

Este projeto Ã© disponibilizado sob **licenÃ§a educacional** para:
- âœ… **Estudo pessoal e acadÃªmico**
- âœ… **Uso em cursos e treinamentos nÃ£o comerciais**
- âœ… **AdaptaÃ§Ã£o para projetos educacionais**
- âœ… **ReferÃªncia em trabalhos acadÃªmicos** (com citaÃ§Ã£o)

---

## Big Data em Python: Casos PrÃ¡ticos de Santa Catarina

*Um guia educacional de Big Data atravÃ©s de storytelling com casos reais de FlorianÃ³polis e regiÃ£o*

*Um guia educacional de Big Data atravÃ©s de storytelling com casos reais de FlorianÃ³polis e regiÃ£o*

---

## ğŸ“– Sobre o Projeto

Este repositÃ³rio apresenta conceitos de **Big Data** e **Python** atravÃ©s de **narrativas educacionais** baseadas em casos reais de Santa Catarina, seguindo o protagonista **Patrick** em suas aventuras com dados.

### ğŸ¯ **Diferenciais**
- **Storytelling educativo**: Aprendizado atravÃ©s de narrativas envolventes
- **Casos reais de SC**: Ponte HercÃ­lio Luz, DETRAN-SC, turismo de Floripa
- **Menos cÃ³digo, mais explicaÃ§Ã£o**: Foco na compreensÃ£o conceitual
- **Contexto local**: Exemplos prÃ¡ticos da Grande FlorianÃ³polis
- **Protagonista Ãºnico**: Patrick como guia consistente em todos os capÃ­tulos

### ğŸ“š **Estrutura do Livro (5 CapÃ­tulos Narrativos)**

#### **Parte I: Fundamentos atravÃ©s de HistÃ³rias**
1. **O Despertar dos Dados** - Patrick descobre Big Data em FlorianÃ³polis âœ…
2. **IoT e Cidades Inteligentes** - Patrick explora sensores em SÃ£o JosÃ© âœ…
3. **AnÃ¡lise de Dados TurÃ­sticos** - Patrick desvenda padrÃµes do turismo âœ…

#### **Parte II: Tecnologias AvanÃ§adas**  
4. **Apache Spark em AÃ§Ã£o** - Patrick processa dados do DETRAN-SC âœ…
5. **Machine Learning Aplicado** - Patrick prevÃª preÃ§os imobiliÃ¡rios âœ…

### ğŸ­ **Metodologia Narrativa**
- **Patrick**: Protagonista Ãºnico e consistente em todos os capÃ­tulos
- **Contexto SC**: Todos os casos baseados em Santa Catarina
- **EducaÃ§Ã£o**: Foco em explicaÃ§Ãµes didÃ¡ticas, nÃ£o em cÃ³digo complexo
- **Aplicabilidade**: Conceitos aplicÃ¡veis a qualquer regiÃ£o do Brasil

---

## ğŸ“ **PÃºblico-Alvo**

- **Estudantes de tecnologia** e ciÃªncia de dados
- **Analistas de dados** iniciantes/intermediÃ¡rios
- **Gestores pÃºblicos** interessados em transformaÃ§Ã£o digital
- **Profissionais** que buscam aprender Big Data de forma didÃ¡tica
- **Qualquer pessoa** interessada em dados e storytelling educativo

---

## ğŸ› ï¸ **Tecnologias e Conceitos Abordados**

### **Linguagens e Frameworks**
- **Python**: Pandas, NumPy, Matplotlib, Seaborn
- **Big Data**: Apache Spark, PySpark, processamento distribuÃ­do
- **Machine Learning**: Scikit-learn, regressÃ£o, classificaÃ§Ã£o
- **Dados**: APIs, CSV, JSON, anÃ¡lise exploratÃ³ria
- **VisualizaÃ§Ã£o**: GrÃ¡ficos interpretativos e storytelling com dados

### **Conceitos Fundamentais**
- Volume, Velocidade, Variedade, Veracidade, Valor (5 V's)
- ETL/ELT e pipelines de dados
- IoT e sensores urbanos
- Smart cities e transformaÃ§Ã£o digital
- Feature engineering e modelagem preditiva

---

## ï¿½ **Palavras-Chave para Profissionais de Big Data e AnÃ¡lise de Dados**

*Skills essenciais que aparecem em vagas de emprego e sÃ£o abordadas neste livro*

### **Linguagens e Frameworks**
Python, PySpark, Apache Spark, SQL, Scala, R, Java, Hadoop, Hive, Apache Kafka, Apache Airflow, Apache Beam, Apache Flink, Databricks, Snowflake, dbt, Great Expectations, MLflow, Kubeflow, TensorFlow, PyTorch, Keras, XGBoost, LightGBM, Scikit-learn, Pandas, NumPy, Matplotlib, Seaborn, Plotly, Streamlit, Dash, FastAPI, Flask, Django

### **Cloud e Infraestrutura**
AWS, Azure, Google Cloud Platform (GCP), Amazon S3, Azure Data Lake, Google BigQuery, Amazon Redshift, Azure Synapse Analytics, Google Cloud Storage, EC2, Azure VM, Google Compute Engine, Lambda, Azure Functions, Google Cloud Functions, Docker, Kubernetes, Terraform, Apache Mesos, Yarn, Spark Cluster, Elasticsearch, MongoDB, Cassandra, Redis, PostgreSQL, MySQL, Oracle, SQL Server

### **Ferramentas de Dados e ETL**
Apache Nifi, Talend, Informatica, Pentaho, SSIS, Azure Data Factory, AWS Glue, Google Cloud Dataflow, Apache Sqoop, Apache Flume, Logstash, Fivetran, Stitch, Airbyte, Singer, Apache Superset, Tableau, Power BI, Looker, Grafana, Metabase, Apache Zeppelin, Jupyter Notebooks, Google Colab, Apache Parquet, Apache Avro, JSON, XML, CSV

### **Machine Learning e IA**
Deep Learning, Neural Networks, CNN, RNN, LSTM, GAN, Transformer, BERT, GPT, Computer Vision, Natural Language Processing (NLP), Time Series Analysis, Recommender Systems, Classification, Regression, Clustering, Dimensionality Reduction, Feature Engineering, Model Selection, Cross-validation, Hyperparameter Tuning, A/B Testing, MLOps, Model Deployment, Model Monitoring, AutoML, Ensemble Methods

### **Metodologias e Conceitos**
Data Engineering, Data Science, Data Analytics, Business Intelligence, ETL/ELT, Data Pipeline, Data Warehouse, Data Lake, Lakehouse, Data Mesh, Real-time Processing, Batch Processing, Stream Processing, Data Governance, Data Quality, Data Lineage, Data Catalog, Metadata Management, GDPR, Data Privacy, Agile, Scrum, DevOps, CI/CD, Git, Version Control

### **EspecializaÃ§Ã£o e Soft Skills**
Statistics, Mathematics, Linear Algebra, Probability, Hypothesis Testing, Statistical Modeling, Experimentation Design, Problem Solving, Critical Thinking, Communication, Data Storytelling, Data Visualization, Business Acumen, Domain Knowledge, Project Management, Teamwork, Leadership, Continuous Learning, Adaptability, Innovation

---

## ï¿½ğŸ“Š **Casos Reais Desenvolvidos**

### ğŸŒ‰ **CapÃ­tulo 1: Despertar dos Dados - Ponte HercÃ­lio Luz**
- Patrick descobre padrÃµes no trÃ¡fego da ponte
- AnÃ¡lise de 2,8 milhÃµes de veÃ­culos/ano
- IntroduÃ§Ã£o aos conceitos de Big Data
- Insights sobre mobilidade urbana em FlorianÃ³polis

### ğŸ™ï¸ **CapÃ­tulo 2: SÃ£o JosÃ© Conectado**  
- Patrick explora sistemas IoT de monitoramento urbano
- Sensores de qualidade do ar e trÃ¡fego
- Conceitos de smart cities aplicados
- TransformaÃ§Ã£o digital em cidades mÃ©dias

### ğŸ–ï¸ **CapÃ­tulo 3: Turismo de FlorianÃ³polis**
- Patrick analisa sazonalidade da ocupaÃ§Ã£o hoteleira
- PadrÃµes de demanda turÃ­stica na Ilha da Magia
- Dados reais de turismo de SC
- PrevisÃ£o e otimizaÃ§Ã£o para o setor

### ğŸš— **CapÃ­tulo 4: DETRAN Santa Catarina**
- Patrick processa 4,2 milhÃµes de veÃ­culos registrados
- IntroduÃ§Ã£o ao Apache Spark e processamento distribuÃ­do
- AnÃ¡lise de frota por municÃ­pio catarinense
- Escalabilidade para grandes volumes de dados

### ğŸ  **CapÃ­tulo 5: Mercado ImobiliÃ¡rio de Floripa**
- Patrick desenvolve Machine Learning para previsÃ£o de preÃ§os
- Fatores de valorizaÃ§Ã£o na Ilha da Magia
- Feature engineering com dados locais
- AplicaÃ§Ã£o prÃ¡tica de algoritmos de ML
- 80+ skills essenciais para o mercado de trabalho

---

## ğŸš€ **Guia PrÃ¡tico: InstalaÃ§Ã£o e Uso**

### **ğŸ“– Guias Completos DisponÃ­veis**

#### **ğŸ› ï¸ [INSTALACAO_COMPLETA.md](./INSTALACAO_COMPLETA.md)**
Tutorial detalhado passo-a-passo para configurar todo ambiente:
- InstalaÃ§Ã£o Python, Java, bibliotecas
- ConfiguraÃ§Ã£o ambiente virtual
- Teste automatizado de validaÃ§Ã£o
- SoluÃ§Ã£o de problemas comuns
- Scripts de verificaÃ§Ã£o completa

#### **ğŸ¤– [GUIA_INTELIGENCIA_ARTIFICIAL.md](./GUIA_INTELIGENCIA_ARTIFICIAL.md)**
Guia completo de IA aplicada a Big Data com casos prÃ¡ticos:
- Machine Learning com dados de SC
- Deep Learning para sÃ©ries temporais
- Processamento de Linguagem Natural (NLP)
- Computer Vision e Algoritmos GenÃ©ticos
- 5 casos prÃ¡ticos prontos para executar

#### **ğŸ¯ [CASOS_PRATICOS.md](./CASOS_PRATICOS.md)**
Projetos completos prontos para usar e adaptar:
- Dashboard interativo com Streamlit
- Sistema de prediÃ§Ã£o de demanda turÃ­stica
- API REST para dados urbanos em tempo real
- Exemplos prÃ¡ticos com cÃ³digo completo
- Algoritmos GenÃ©ticos para otimizaÃ§Ã£o
- Projetos avanÃ§ados e prÃ³ximos passos

### **ğŸ“‹ PrÃ©-requisitos**

**Sistema Operacional:**
- Windows 10/11, macOS 10.15+, ou Linux Ubuntu 18.04+

**Software Essencial:**
- **Python 3.8+** - [Download aqui](https://python.org/downloads)
- **Java 8 ou 11** (para PySpark) - [Download OpenJDK](https://adoptium.net/)
- **Git** - [Download aqui](https://git-scm.com/downloads)

**Verificar InstalaÃ§Ãµes:**
```bash
# Verificar Python
python --version
# Deve mostrar: Python 3.8.x ou superior

# Verificar Java  
java -version
# Deve mostrar: openjdk version "8" ou "11"

# Verificar Git
git --version
```

---

### **âš¡ InstalaÃ§Ã£o RÃ¡pida (5 minutos)**

#### **Passo 1: Clone o RepositÃ³rio**
```bash
# Abra o terminal/prompt de comando
git clone https://github.com/cordeirotelecom/topicos-bigdata-python.git
cd topicos-bigdata-python
```

#### **Passo 2: Crie um Ambiente Virtual (Recomendado)**
```bash
# Windows
python -m venv venv
venv\Scripts\activate

# macOS/Linux  
python3 -m venv venv
source venv/bin/activate
```

#### **Passo 3: Instale as DependÃªncias**
```bash
# Instalar todas as bibliotecas necessÃ¡rias
pip install -r requirements.txt

# Verificar se PySpark foi instalado corretamente
python -c "import pyspark; print('PySpark OK!')"
```

#### **Passo 4: Teste a InstalaÃ§Ã£o**
```bash
# Iniciar Jupyter Lab
jupyter lab

# Ou Jupyter Notebook clÃ¡ssico
jupyter notebook
```

---

### **ğŸ“– Como Usar: Guia Passo a Passo**

#### **Para Iniciantes Completos**

**1. Comece pelo CapÃ­tulo 1**
```bash
# Navegue atÃ© a pasta do livro
cd livro/

# Abra o primeiro capÃ­tulo
# Windows: notepad capitulo01-despertar-dos-dados.md
# macOS: open capitulo01-despertar-dos-dados.md  
# Linux: gedit capitulo01-despertar-dos-dados.md
```

**2. Siga a Ordem dos CapÃ­tulos**
- ğŸ“– **CapÃ­tulo 1**: Conceitos bÃ¡sicos de Big Data
- ğŸ™ï¸ **CapÃ­tulo 2**: IoT e sensores urbanos
- ğŸ–ï¸ **CapÃ­tulo 3**: AnÃ¡lise de dados turÃ­sticos
- âš¡ **CapÃ­tulo 4**: Processamento distribuÃ­do com Spark
- ğŸ¤– **CapÃ­tulo 5**: Machine Learning aplicado

**3. Experimente os Conceitos**
```python
# Exemplo prÃ¡tico do CapÃ­tulo 1
import pandas as pd
import matplotlib.pyplot as plt

# Simular dados de trÃ¡fego da Ponte HercÃ­lio Luz
dados_ponte = {
    'hora': range(0, 24),
    'veiculos': [50, 30, 20, 25, 45, 120, 350, 500, 
                 400, 300, 250, 280, 320, 300, 350, 
                 400, 500, 600, 450, 300, 200, 150, 100, 70]
}

df = pd.DataFrame(dados_ponte)
plt.plot(df['hora'], df['veiculos'])
plt.title('TrÃ¡fego na Ponte HercÃ­lio Luz - 24h')
plt.xlabel('Hora do Dia')
plt.ylabel('NÃºmero de VeÃ­culos')
plt.show()
```

### **ğŸ’¡ Exemplos PrÃ¡ticos RÃ¡pidos**

#### **ğŸ™ï¸ AnÃ¡lise de IoT - Sensores em SÃ£o JosÃ©**
```python
import pandas as pd
import numpy as np

# Simular dados de sensores de qualidade do ar
np.random.seed(42)
horas = pd.date_range('2025-01-01', periods=168, freq='H')  # 1 semana

dados_iot = pd.DataFrame({
    'timestamp': horas,
    'pm25': np.random.normal(25, 8, 168),  # PM2.5 (Î¼g/mÂ³)
    'temperatura': 20 + 10 * np.sin(np.arange(168) * 2 * np.pi / 24) + np.random.normal(0, 2, 168),
    'umidade': 60 + 20 * np.sin(np.arange(168) * 2 * np.pi / 24 + np.pi/4) + np.random.normal(0, 5, 168)
})

# AnÃ¡lise rÃ¡pida
print("ğŸ“Š Qualidade do Ar - SÃ£o JosÃ© SC")
print(f"PM2.5 mÃ©dio: {dados_iot['pm25'].mean():.1f} Î¼g/mÂ³")
print(f"Temperatura mÃ©dia: {dados_iot['temperatura'].mean():.1f}Â°C")
print(f"Dias com qualidade ruim (PM2.5 > 35): {(dados_iot['pm25'] > 35).sum()}")

# VisualizaÃ§Ã£o
import matplotlib.pyplot as plt
plt.figure(figsize=(12, 4))
plt.subplot(1, 3, 1)
plt.plot(dados_iot['pm25'])
plt.title('PM2.5')
plt.subplot(1, 3, 2)
plt.plot(dados_iot['temperatura'])
plt.title('Temperatura')
plt.subplot(1, 3, 3)
plt.plot(dados_iot['umidade'])
plt.title('Umidade')
plt.tight_layout()
plt.show()
```

#### **ğŸ–ï¸ Machine Learning - Turismo Floripa**
```python
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split

# Dados sintÃ©ticos de ocupaÃ§Ã£o hoteleira
np.random.seed(42)
dados_turismo = pd.DataFrame({
    'mes': np.random.randint(1, 13, 1000),
    'dia_semana': np.random.randint(1, 8, 1000),
    'temperatura': np.random.normal(25, 5, 1000),
    'chuva': np.random.choice([0, 1], 1000, p=[0.7, 0.3]),
    'feriado': np.random.choice([0, 1], 1000, p=[0.9, 0.1])
})

# Simular ocupaÃ§Ã£o baseada nas features
ocupacao = (
    50 +  # base
    dados_turismo['mes'].apply(lambda x: 30 if x in [12, 1, 2] else 0) +  # verÃ£o
    dados_turismo['dia_semana'].apply(lambda x: 20 if x in [6, 7] else 0) +  # fim de semana
    dados_turismo['temperatura'] * 0.5 +  # temperatura
    dados_turismo['feriado'] * 25 -  # feriados
    dados_turismo['chuva'] * 15 +  # chuva reduz ocupaÃ§Ã£o
    np.random.normal(0, 10, 1000)  # ruÃ­do
)
dados_turismo['ocupacao'] = np.clip(ocupacao, 0, 100)

# Treinar modelo
X = dados_turismo[['mes', 'dia_semana', 'temperatura', 'chuva', 'feriado']]
y = dados_turismo['ocupacao']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

modelo = RandomForestRegressor(n_estimators=100, random_state=42)
modelo.fit(X_train, y_train)

# PrediÃ§Ã£o para um fim de semana de verÃ£o
predicao = modelo.predict([[1, 7, 28, 0, 0]])  # Janeiro, domingo, 28Â°C, sem chuva, sem feriado
print(f"ğŸ¨ OcupaÃ§Ã£o prevista: {predicao[0]:.1f}%")

# ImportÃ¢ncia das variÃ¡veis
importancias = pd.DataFrame({
    'variavel': X.columns,
    'importancia': modelo.feature_importances_
}).sort_values('importancia', ascending=False)
print("\nğŸ“ˆ Fatores mais importantes:")
for _, row in importancias.iterrows():
    print(f"{row['variavel']}: {row['importancia']:.3f}")
```

#### **âš¡ Big Data com PySpark - DETRAN SC**
```python
from pyspark.sql import SparkSession
from pyspark.sql.functions import col, count, avg

# Inicializar Spark
spark = SparkSession.builder \
    .appName("DETRAN-SC Analysis") \
    .config("spark.sql.adaptive.enabled", "true") \
    .getOrCreate()

# Simular dados de veÃ­culos de SC
dados_veiculos = [
    ("FlorianÃ³polis", "Carro", 2023, 45000, "Gasoline"),
    ("SÃ£o JosÃ©", "Moto", 2023, 12000, "Gasoline"),
    ("PalhoÃ§a", "Carro", 2022, 18000, "Flex"),
    ("BiguaÃ§u", "Carro", 2023, 8000, "Flex"),
    ("FlorianÃ³polis", "Moto", 2022, 25000, "Gasoline"),
    ("SÃ£o JosÃ©", "Carro", 2023, 22000, "Electric"),
    ("Laguna", "Carro", 2021, 5000, "Gasoline"),
    ("Joinville", "Carro", 2023, 35000, "Flex"),
    ("Blumenau", "Moto", 2023, 15000, "Gasoline"),
    ("ItajaÃ­", "Carro", 2022, 12000, "Flex")
]

colunas = ["cidade", "tipo", "ano", "quantidade", "combustivel"]
df_veiculos = spark.createDataFrame(dados_veiculos, colunas)

print("ğŸš— AnÃ¡lise de Frota - DETRAN SC")
print("=" * 40)

# AnÃ¡lise por cidade
print("\nğŸ“ VeÃ­culos por cidade:")
df_veiculos.groupBy("cidade") \
    .agg(count("*").alias("registros"), 
         sum("quantidade").alias("total_veiculos")) \
    .orderBy(col("total_veiculos").desc()) \
    .show()

# AnÃ¡lise por tipo de combustÃ­vel
print("â›½ DistribuiÃ§Ã£o por combustÃ­vel:")
df_veiculos.groupBy("combustivel") \
    .agg(sum("quantidade").alias("total")) \
    .orderBy(col("total").desc()) \
    .show()

# TendÃªncia de eletrificaÃ§Ã£o
print("ğŸ”‹ VeÃ­culos elÃ©tricos:")
df_veiculos.filter(col("combustivel") == "Electric").show()

spark.stop()
```

---

#### **Para UsuÃ¡rios IntermediÃ¡rios**

**1. Explore os Dados PrÃ¡ticos**
```python
# Exemplo do CapÃ­tulo 4: Spark com dados do DETRAN-SC
from pyspark.sql import SparkSession

# Inicializar Spark
spark = SparkSession.builder \
    .appName("DETRAN-SC Analysis") \
    .getOrCreate()

# Simular dados de veÃ­culos de SC
dados_veiculos = [
    ("FlorianÃ³polis", "Carro", 2020, 15000),
    ("SÃ£o JosÃ©", "Moto", 2021, 8000),
    ("PalhoÃ§a", "Carro", 2022, 12000),
    ("BiguaÃ§u", "Moto", 2020, 3000)
]

colunas = ["cidade", "tipo", "ano", "quantidade"]
df_spark = spark.createDataFrame(dados_veiculos, colunas)

# AnÃ¡lise por cidade
df_spark.groupBy("cidade").sum("quantidade").show()
```

**2. Aplique Machine Learning**
```python
# Exemplo do CapÃ­tulo 5: ML para preÃ§os imobiliÃ¡rios
from sklearn.linear_model import LinearRegression
import numpy as np

# Dados simulados de imÃ³veis em Floripa
area = np.array([60, 80, 120, 150, 200]).reshape(-1, 1)
preco = np.array([400000, 550000, 750000, 900000, 1200000])

# Treinar modelo
modelo = LinearRegression()
modelo.fit(area, preco)

# Predizer preÃ§o para apartamento de 100mÂ²
preco_100m2 = modelo.predict([[100]])
print(f"PreÃ§o estimado para 100mÂ²: R$ {preco_100m2[0]:,.0f}")
```

---

### **ğŸ”§ SoluÃ§Ã£o de Problemas Comuns**

#### **Erro: Java nÃ£o encontrado**
```bash
# Verificar JAVA_HOME
echo $JAVA_HOME  # Linux/macOS
echo %JAVA_HOME%  # Windows

# Se vazio, definir manualmente:
export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64  # Linux
export JAVA_HOME=/Library/Java/JavaVirtualMachines/adoptopenjdk-8.jdk/Contents/Home  # macOS
```

#### **Erro: PySpark nÃ£o inicializa**
```python
# ConfiguraÃ§Ã£o manual do PySpark
import os
os.environ['JAVA_HOME'] = '/caminho/para/java'
os.environ['SPARK_HOME'] = '/caminho/para/spark'

import findspark
findspark.init()

import pyspark
```

#### **Erro: MÃ³dulo nÃ£o encontrado**
```bash
# Reinstalar dependÃªncias
pip install --upgrade -r requirements.txt

# Verificar se estÃ¡ no ambiente virtual correto
which python  # Linux/macOS
where python   # Windows
```

---

### **ğŸ“± Testando Sua InstalaÃ§Ã£o - Checklist Completo**

**âœ… Teste 1: Python e Pandas**
```python
import pandas as pd
print("âœ… Pandas funcionando!")
df = pd.DataFrame({'nome': ['Patrick'], 'cidade': ['FlorianÃ³polis']})
print(df)
```

**âœ… Teste 2: VisualizaÃ§Ã£o**
```python
import matplotlib.pyplot as plt
import numpy as np

x = np.linspace(0, 10, 100)
y = np.sin(x)
plt.plot(x, y)
plt.title("âœ… Matplotlib funcionando!")
plt.show()
```

**âœ… Teste 3: Big Data (PySpark)**
```python
from pyspark.sql import SparkSession

spark = SparkSession.builder.appName("Teste").getOrCreate()
df = spark.createDataFrame([("Patrick", "FlorianÃ³polis")], ["nome", "cidade"])
df.show()
print("âœ… PySpark funcionando!")
spark.stop()
```

**âœ… Teste 4: Machine Learning**
```python
from sklearn.datasets import make_classification
from sklearn.linear_model import LogisticRegression

X, y = make_classification(n_samples=100, n_features=2, n_redundant=0, random_state=42)
model = LogisticRegression()
model.fit(X, y)
print("âœ… Scikit-learn funcionando!")
```

---

### **ğŸ“š PrÃ³ximos Passos ApÃ³s InstalaÃ§Ã£o**

1. **ğŸ“– Leia o CapÃ­tulo 1** - Entenda a jornada de Patrick
2. **ğŸ’» Abra Jupyter Lab** - Ambiente interativo para experimentar
3. **ğŸ” Explore os dados** - Cada capÃ­tulo tem exemplos prÃ¡ticos
4. **ğŸ› ï¸ Adapte para sua regiÃ£o** - Use os conceitos em seus projetos
5. **ğŸ¤ Compartilhe resultados** - Contribua com a comunidade

---

## ğŸ“ˆ **EspecificaÃ§Ãµes TÃ©cnicas do Projeto**

### **ğŸ“‹ Requisitos de Sistema**
- **Sistema Operacional**: Windows 10+, macOS 10.15+, Ubuntu 18.04+
- **Python**: 3.8, 3.9, 3.10 ou 3.11 (testado)
- **Java**: OpenJDK 8 ou 11 (para PySpark)
- **RAM**: MÃ­nimo 4GB (recomendado 8GB+)
- **EspaÃ§o em Disco**: 2GB livres

### **ğŸ“¦ DependÃªncias Principais**
```txt
pandas>=2.1.0          # AnÃ¡lise de dados
numpy>=1.24.0           # ComputaÃ§Ã£o numÃ©rica  
matplotlib>=3.7.0       # VisualizaÃ§Ã£o bÃ¡sica
seaborn>=0.12.0         # VisualizaÃ§Ã£o estatÃ­stica
pyspark>=3.5.0          # Big Data processing
scikit-learn>=1.3.0     # Machine Learning
jupyter>=1.0.0          # Notebooks interativos
```

### **â±ï¸ Tempo de InstalaÃ§Ã£o**
- **InstalaÃ§Ã£o bÃ¡sica**: 5-10 minutos
- **ConfiguraÃ§Ã£o Java**: 2-5 minutos
- **Teste completo**: 3-5 minutos
- **Total**: 15-20 minutos

### **ğŸ“Š Estrutura do ConteÃºdo**
- **5 CapÃ­tulos narrativos**: 60+ pÃ¡ginas
- **Exemplos prÃ¡ticos**: 20+ cÃ³digos testados
- **Casos reais**: Dados de Santa Catarina
- **NÃ­vel**: Iniciante â†’ IntermediÃ¡rio
- **DuraÃ§Ã£o estudo**: 8-12 horas

### **ğŸ¯ Compatibilidade Testada**
```bash
âœ… Windows 10/11 + Python 3.9 + Java 8
âœ… macOS Monterey + Python 3.10 + Java 11  
âœ… Ubuntu 20.04 + Python 3.8 + Java 8
âœ… Google Colab (online, sem instalaÃ§Ã£o)
âœ… Jupyter Lab + VSCode + PyCharm
```

---

## ğŸŒŸ **Depoimentos (Baseados no Projeto)**

*"Finalmente um repositÃ³rio que explica Big Data atravÃ©s de histÃ³rias! Patrick torna o aprendizado muito mais envolvente."* - **Estudante de CiÃªncia de Dados**

*"Os casos de Santa Catarina sÃ£o perfeitos para entender como aplicar esses conceitos na nossa realidade brasileira."* - **Analista de Dados**

*"A abordagem de menos cÃ³digo e mais explicaÃ§Ã£o foi fundamental para compreender os conceitos de verdade."* - **Gestor PÃºblico**

*"Patrick como personagem Ãºnico dÃ¡ consistÃªncia e facilita o acompanhamento de toda a jornada de aprendizado."* - **Professor de Tecnologia**

---

## ğŸ¤ **Contribuindo para o Projeto**

Este repositÃ³rio estÃ¡ em **constante evoluÃ§Ã£o educativa**:

1. **Leia e dÃª feedback** sobre a clareza das explicaÃ§Ãµes
2. **Sugira melhorias** na narrativa ou nos conceitos
3. **Compartilhe** como aplicou os conhecimentos em seus projetos
4. **Adapte** os casos para sua regiÃ£o e compartilhe os resultados
5. **Contribua** com novos casos prÃ¡ticos baseados em storytelling

### **Como Contribuir**
- Abra issues com sugestÃµes de melhoria
- Proponha novos casos baseados em dados reais
- Sugira melhorias na consistÃªncia narrativa
- Compartilhe aplicaÃ§Ãµes prÃ¡ticas dos conceitos

---

## ğŸ“ **Sobre o Projeto**

- **Metodologia**: Storytelling educativo para ensino de Big Data
- **Protagonista**: Patrick - personagem consistente em todos os capÃ­tulos
- **LocalizaÃ§Ã£o**: Casos baseados em Santa Catarina, aplicÃ¡veis universalmente
- **Objetivo**: Democratizar conhecimento em Big Data atravÃ©s de narrativas envolventes
- **Diferencial**: Foco em compreensÃ£o conceitual, nÃ£o em cÃ³digo complexo

---

## ğŸ“„ **LicenÃ§a e Uso**

Este conteÃºdo Ã© disponibilizado para fins **educacionais e nÃ£o comerciais**. 

### **Uso Permitido**
- Estudo pessoal e acadÃªmico
- AdaptaÃ§Ã£o dos conceitos para projetos prÃ³prios
- Compartilhamento com fins educativos
- ReferÃªncia em trabalhos acadÃªmicos (com citaÃ§Ã£o)

**Desenvolvido com â¤ï¸ em Santa Catarina para estudantes e profissionais de Big Data.**

---

### ğŸ¯ **EstatÃ­sticas do Projeto**
- **15 Aulas completas** - Do bÃ¡sico ao avanÃ§ado
- **5 MÃ³dulos especializados** - Fundamentos, Hadoop, Spark, Pandas, ML
- **40+ QuestÃµes de concurso** - PreparaÃ§Ã£o profissional
- **5 CapÃ­tulos narrativos** - Storytelling com Patrick
- **20+ Exemplos prÃ¡ticos** - CÃ³digos funcionais
- **100% PortuguÃªs** - ConteÃºdo nacional
- **Casos reais SC** - AplicaÃ§Ã£o prÃ¡tica local

**Ãšltima atualizaÃ§Ã£o: 29/09/2025** âœ…
#   S i t e   r e b u i l d   0 9 / 2 5 / 2 0 2 5   1 2 : 2 1 : 5 8 
 
 #   D e p l o y   t r i g g e r   0 9 / 2 5 / 2 0 2 5   1 3 : 4 2 : 2 3 
 
 