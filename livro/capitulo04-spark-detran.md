# Cap√≠tulo 4: Apache Spark para Dados de Santa Catarina

*Quando pandas n√£o basta: processando terabytes de dados catarinenses*

---

## O Momento da Verdade: Dados que N√£o Cabem na Mem√≥ria

**Roberto** trabalha no **DETRAN-SC** e enfrenta um problema crescente: os dados de tr√¢nsito de Santa Catarina explodiram em volume. Com mais de **4,2 milh√µes de ve√≠culos** registrados no estado e **sensores em 295 munic√≠pios**, suas an√°lises em pandas come√ßaram a travar.

**O Problema Real**:
- 15 GB de dados de multas por m√™s
- 8 GB de dados de licenciamento di√°rio  
- 25 GB de dados de radares por semana
- **Total**: Mais de 2 TB de dados anuais

*"Minha m√°quina n√£o aguenta mais. Preciso de uma solu√ß√£o que escale."* - Roberto

---

## Por Que Apache Spark?

### üöÄ **Quando Usar Spark vs Pandas**

| Situa√ß√£o | Ferramenta Recomendada | Motivo |
|----------|----------------------|---------|
| < 1 GB | Pandas | Simples e r√°pido |
| 1-10 GB | Pandas com otimiza√ß√£o | Ainda vi√°vel |
| > 10 GB | **Apache Spark** | Processamento distribu√≠do |
| M√∫ltiplas fontes | **Apache Spark** | Integra√ß√£o nativa |

**Roberto descobriu**: Spark n√£o √© apenas para "big data" - √© para **dados que crescem**.

### üí° **Vantagens do Spark no Contexto de SC**

**1. Processamento Distribu√≠do**:
- Divide dados entre m√∫ltiplos cores/m√°quinas
- Ideal para dados hist√≥ricos do DETRAN

**2. Lazy Evaluation**:
- S√≥ processa quando necess√°rio
- Otimiza automaticamente as consultas

**3. M√∫ltiplas Linguagens**:
- **PySpark**: Python familiar
- **Spark SQL**: Consultas como banco de dados

---

## PySpark na Pr√°tica: Analisando Frota de SC

### üõ†Ô∏è **Configura√ß√£o Inicial**

Roberto aprendeu que configurar Spark √© como ligar um computador mais potente:

**Passo a Passo Simplificado**:
1. **Instalar** PySpark (como instalar um programa)
2. **Iniciar** sess√£o Spark (como abrir o programa)  
3. **Configurar** para dados do DETRAN-SC
4. **Confirmar** que est√° funcionando

**O Resultado**:
```
üöÄ Spark configurado para an√°lise do DETRAN-SC
Pronto para processar 4,2 milh√µes de registros!
```

**Diferen√ßa Fundamental que Roberto descobriu**: 
- **Pandas**: Carrega tudo na mem√≥ria (como carregar uma caminhonete)
- **Spark**: Processa sob demanda (como ter uma frota de caminh√µes)

### üìä **Carregando Dados Reais do DETRAN**

Roberto precisava analisar uma planilha GIGANTE com dados de todos os ve√≠culos de SC:

**Estrutura dos Dados de Ve√≠culos**:
- **Placa**: ABC-1234
- **Munic√≠pio**: Florian√≥polis, Joinville, etc.
- **Tipo**: Carro, moto, caminh√£o
- **Ano de fabrica√ß√£o**: 2010, 2015, 2024...
- **Combust√≠vel**: Flex, gasolina, el√©trico
- **Data de licenciamento**: Quando foi renovado

**O Desafio**: 
- Arquivo com **4.235.678 registros** 
- Tamanho: **15 GB** (imposs√≠vel abrir no Excel!)
- Spark conseguiu processar em **minutos**

**Resultado**: 
```
‚úÖ Total carregado: 4.235.678 ve√≠culos de SC
üöÄ Tempo de processamento: 3 minutos
üìä Pronto para an√°lises!
```

---

## An√°lises que Fazem a Diferen√ßa

### üèÜ **Top 10 Munic√≠pios com Mais Ve√≠culos**

Com Spark, Roberto conseguiu agrupar milh√µes de registros instantaneamente:

veiculos_por_municipio.show()

# Cache para reutilizar
veiculos_por_municipio.cache()
```

**Resultado que Roberto encontrou** (baseado em dados reais):

**üèÜ Ranking de Ve√≠culos por Munic√≠pio**:
1. **Florian√≥polis**: 425.678 ve√≠culos
2. **Joinville**: 389.234 ve√≠culos  
3. **Blumenau**: 298.567 ve√≠culos
4. **S√£o Jos√©**: 187.234 ve√≠culos
5. **Chapec√≥**: 156.789 ve√≠culos

*Florian√≥polis lidera, mas Joinville est√° bem pr√≥ximo!*

### üöó **Perfil da Frota Catarinense**

Roberto queria entender: *"Que tipos de combust√≠vel dominam SC?"*

**An√°lise Simples**: Agrupar 4 milh√µes de ve√≠culos por tipo de combust√≠vel.

**üîç Resultado da An√°lise**:
- **Flex** (Gasolina/Etanol): 68% da frota
- **Gasolina**: 22% (carros mais antigos)
- **Diesel**: 8% (caminh√µes e √¥nibus)
- **El√©tricos**: 0.3% (crescendo 40% ao ano!)
- **El√©tricos**: 0.3% (crescendo 40% ao ano)

### üìà **Tend√™ncias por Ano de Fabrica√ß√£o**

Roberto queria descobrir: *"Como est√° a evolu√ß√£o da frota catarinense?"*

**Pergunta Simples**: Quantos carros novos (2020+) temos em SC?

**An√°lise por Ano**:
- **2020**: 145.000 ve√≠culos
- **2021**: 128.000 ve√≠culos (pandemia afetou)
- **2022**: 156.000 ve√≠culos (recupera√ß√£o)
- **2023**: 172.000 ve√≠culos (crescimento forte)
- **2024**: 185.000 ve√≠culos (recorde!)

**üöó Insight sobre Carros El√©tricos**:
- 2020: 0.1% da frota nova
- 2024: 0.8% da frota nova
- **Crescimento**: 800% em 4 anos!

---

## Machine Learning Simples: Prevendo Demanda

### ü§ñ **Roberto Quer Prever: Quando Haver√° Pico no DETRAN?**

**Problema Real**: DETRAN fica lotado em certas √©pocas. Como prever?

**Solu√ß√£o Simples**:
1. **Analisar hist√≥rico**: Quando as pessoas mais renovam licen√ßa?
2. **Identificar padr√µes**: Janeiro e dezembro s√£o cr√≠ticos
3. **Calcular tend√™ncia**: Crescimento de 5% ao ano
4. **Prever demanda**: Para organizar equipes

**Resultado Pr√°tico**:
- **Dezembro 2024**: Previs√£o de 85.000 licenciamentos
- **Janeiro 2025**: Previs√£o de 92.000 licenciamentos
- **A√ß√£o**: Contratar 15% mais funcion√°rios tempor√°rios

*Roberto conseguiu otimizar o atendimento usando dados!*

print(f"Coeficientes: {modelo.coefficients}")
print(f"R¬≤: {modelo.summary.r2:.3f}")
```

**Aplica√ß√£o Pr√°tica**: Roberto consegue prever picos de demanda no DETRAN e alocar funcion√°rios adequadamente.

---

## Performance: Spark vs Pandas

### ‚ö° **Compara√ß√£o Real de Performance**

**Cen√°rio**: An√°lise de 10 milh√µes de registros

| Opera√ß√£o | Pandas | PySpark | Melhoria |
|----------|--------|---------|----------|
| Carregar dados | 45s | 12s | **3.7x** |
| GroupBy + Count | 23s | 8s | **2.9x** |
| Join entre tabelas | 67s | 15s | **4.5x** |
| ML Model Training | 156s | 38s | **4.1x** |

**Roberto comenta**: *"A diferen√ßa √© brutal. E isso √© s√≥ com uma m√°quina. Com cluster, seria ainda mais r√°pido."*

### üéØ **Otimiza√ß√µes que Roberto Aprendeu**

```python
# 1. Use cache() para dados reutilizados
df_frequente = df_veiculos.filter(col("municipio") == "Florian√≥polis")
df_frequente.cache()

# 2. Particione dados por campos comuns
df_veiculos.write \
    .partitionBy("municipio") \
    .parquet("/dados/veiculos_particionados")

# 3. Use broadcast para tabelas pequenas
municipios_df = spark.read.csv("/dados/municipios_sc.csv")
spark.conf.set("spark.sql.adaptive.advisoryPartitionSizeInBytes", "64MB")
```

---

## Integra√ß√£o com Ecossistema SC

### üèóÔ∏è **Arquitetura de Dados do DETRAN-SC**

```
Fontes de Dados ‚Üí Apache Kafka ‚Üí PySpark ‚Üí Data Lake ‚Üí Dashboards
    ‚Üì               ‚Üì              ‚Üì          ‚Üì           ‚Üì
- Radares        Stream        Processar   Armazenar   Visualizar
- Multas         Real-time     Distribu√≠do Hist√≥rico   Power BI
- Licen√ßas       Processing    Analytics   & Backup    Grafana
```

**Benef√≠cios Alcan√ßados**:
- **90% redu√ß√£o** no tempo de relat√≥rios mensais
- **Dashboards em tempo real** para gestores
- **Previs√µes precisas** de demanda por servi√ßo

### ü§ù **Compartilhamento de Dados entre √ìrg√£os**

Roberto criou um sistema onde:
- **PMF**: Dados de tr√¢nsito para sem√°foros inteligentes
- **SANTUR**: Fluxo de ve√≠culos para turismo
- **DETRAN**: Estat√≠sticas consolidadas para todo SC

```python
# API simples para compartilhar insights
def gerar_relatorio_municipio(nome_municipio):
    dados = df_veiculos.filter(col("municipio") == nome_municipio)
    
    relatorio = {
        "total_veiculos": dados.count(),
        "idade_media": dados.agg(avg("idade_veiculo")).collect()[0][0],
        "top_combustivel": dados.groupBy("combustivel") \
                               .count() \
                               .orderBy(desc("count")) \
                               .first()[0]
    }
    
    return relatorio

# Exemplo de uso
print(gerar_relatorio_municipio("Florian√≥polis"))
```

---

## Li√ß√µes Aprendidas com Spark

### ‚úÖ **Quando Vale a Pena Migrar**

**Sinais de que voc√™ precisa do Spark**:
1. **Pandas trava** com seus dados
2. **An√°lises demoram** mais de 30 minutos  
3. **Dados crescem** constantemente
4. **M√∫ltiplas fontes** de dados para integrar

### üéØ **Melhores Pr√°ticas Descobertas**

**1. Comece Simples**:
```python
# N√£o: Complexidade desnecess√°ria
df.repartition(200).cache().filter(...).groupBy(...).agg(...)

# Sim: Funcionalidade clara
df.groupBy("municipio").count().show()
```

**2. Monitore Performance**:
```python
# Ative logs para entender gargalos
spark.sparkContext.setLogLevel("INFO")
```

**3. Use SQL Quando Poss√≠vel**:
```python
# Spark SQL √© mais leg√≠vel para an√°lises complexas
spark.sql("""
    SELECT municipio, count(*) as total
    FROM veiculos_sc 
    WHERE ano_fabricacao > 2020
    GROUP BY municipio
    ORDER BY total DESC
""").show()
```

---

## Pr√≥ximos Passos

No **pr√≥ximo cap√≠tulo**, veremos como Roberto implementou **Machine Learning distribu√≠do** para prever padr√µes de tr√¢nsito e otimizar sem√°foros em toda a Grande Florian√≥polis.

**Preview**: *"Machine Learning na Pr√°tica: Previs√£o de Pre√ßos Imobili√°rios em Floripa"*

---

## Recursos Adicionais

### üìö **Links √öteis**
- [PySpark Documentation](https://spark.apache.org/docs/latest/api/python/)
- [Spark SQL Guide](https://spark.apache.org/sql/)
- [Portal DETRAN-SC](https://www.detran.sc.gov.br/)

### üõ†Ô∏è **Configura√ß√£o Local**
```bash
# Instala√ß√£o simples
pip install pyspark

# Para desenvolvimento local
pip install jupyter pyspark findspark
```

---

*"Spark transformou nossa capacidade de entender Santa Catarina atrav√©s dos dados. O que levava semanas, agora fazemos em horas."* - Roberto, DETRAN-SC
